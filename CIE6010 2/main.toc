\select@language {english}
\vskip -8pt
\contentsline {schapter}{Acknowledgments}{ix}{chapter*.2}
\vskip -8pt
\contentsline {schapter}{Notations}{xi}{chapter*.3}
\contentsline {chapter}{\numberline {1}Week1}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Monday}{1}{section.1.1}
\contentsline {subsection}{\numberline {1.1.1}Introduction to Optimizaiton}{1}{subsection.1.1.1}
\contentsline {section}{\numberline {1.2}Wednesday}{2}{section.1.2}
\contentsline {subsection}{\numberline {1.2.1}Reviewing for Linear Algebra}{2}{subsection.1.2.1}
\contentsline {subsection}{\numberline {1.2.2}Reviewing for Calculus}{2}{subsection.1.2.2}
\contentsline {subsection}{\numberline {1.2.3}Introduction to Optimization}{3}{subsection.1.2.3}
\contentsline {chapter}{\numberline {2}Week2}{7}{chapter.2}
\contentsline {section}{\numberline {2.1}Monday}{7}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Reviewing and Announments}{7}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Quadratic Function Case Study}{8}{subsection.2.1.2}
\contentsline {paragraph}{Least Squares Problem}{8}{Item.4}
\contentsline {paragraph}{A Non-trival Quadratic Function}{9}{Item.4}
\contentsline {paragraph}{A Non-trival Function Study}{10}{Item.4}
\contentsline {section}{\numberline {2.2}Wednesday}{11}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Convex Analysis}{11}{subsection.2.2.1}
\contentsline {chapter}{\numberline {3}Week3}{17}{chapter.3}
\contentsline {section}{\numberline {3.1}Wednesday}{17}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}Convex Analysis}{17}{subsection.3.1.1}
\contentsline {subsection}{\numberline {3.1.2}Iterative Method}{18}{subsection.3.1.2}
\contentsline {paragraph}{Nonlinear LS}{19}{Item.18}
\contentsline {paragraph}{Choice of Step Length $\alpha $}{19}{Item.18}
\contentsline {paragraph}{Convergence Rate Analysis}{21}{definitionT.3.3}
\contentsline {paragraph}{Choice of Step Length}{21}{definitionT.3.3}
\contentsline {section}{\numberline {3.2}Thursday}{22}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Announcement}{22}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Sparse Large Scale Optimization}{22}{subsection.3.2.2}
\contentsline {paragraph}{Linear Programming Approach}{22}{subsection.3.2.2}
\contentsline {paragraph}{Gredient-Based Approach}{23}{Item.20}
\contentsline {paragraph}{Descent Direction}{23}{equation.3.2.1}
\contentsline {paragraph}{Stopping Criteria}{24}{equation.3.2.1}
\contentsline {paragraph}{Armijo Condition and BB Step}{24}{Item.23}
\contentsline {chapter}{\numberline {4}Week4}{27}{chapter.4}
\contentsline {section}{\numberline {4.1}Wednesday}{27}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Comments for MATLAB Project}{27}{subsection.4.1.1}
\contentsline {paragraph}{Do Not Repeat Computation}{27}{subsection.4.1.1}
\contentsline {paragraph}{Arrange Computation Properly}{27}{subsection.4.1.1}
\contentsline {paragraph}{Appreciate sparsity}{27}{subsection.4.1.1}
\contentsline {paragraph}{Grading Criteria}{27}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Local Convergence Rate}{28}{subsection.4.1.2}
\contentsline {subsection}{\numberline {4.1.3}Newton's Method}{29}{subsection.4.1.3}
\contentsline {paragraph}{Interpretation}{29}{equation.4.1.1}
\contentsline {paragraph}{Convergence of Rate}{29}{equation.4.1.1}
\contentsline {subsection}{\numberline {4.1.4}Tutorial: Introduction to Convexity}{30}{subsection.4.1.4}
\contentsline {paragraph}{Convexity Examples}{31}{Item.31}
\contentsline {paragraph}{Announcement}{31}{Item.31}
\contentsline {chapter}{\numberline {5}Week5}{33}{chapter.5}
\contentsline {section}{\numberline {5.1}Monday}{33}{section.5.1}
\contentsline {subsection}{\numberline {5.1.1}Review}{33}{subsection.5.1.1}
\contentsline {paragraph}{Optimality Condition}{33}{subsection.5.1.1}
\contentsline {paragraph}{Iterative descent methods}{34}{subsection.5.1.1}
\contentsline {paragraph}{Reading materials}{34}{subsection.5.1.1}
\contentsline {paragraph}{Step-size}{34}{subsection.5.1.1}
\contentsline {paragraph}{Local convergence rate}{35}{subsection.5.1.1}
\contentsline {paragraph}{Finite difference Method}{35}{subsection.5.1.1}
\contentsline {subsection}{\numberline {5.1.2}Existence of solution to Quadratic Programming}{36}{subsection.5.1.2}
\contentsline {paragraph}{Asymptotic Directions are essentially Boundary Directions}{37}{equation.5.1.1}
\contentsline {paragraph}{Finiteness of optimal value}{38}{equation.5.1.4}
\contentsline {paragraph}{Feasibleness of $\bm {x}^k-\alpha \bm {d}$}{38}{equation.5.1.4}
\contentsline {section}{\numberline {5.2}Wednesday}{39}{section.5.2}
\contentsline {paragraph}{Announcement}{39}{section.5.2}
\contentsline {subsection}{\numberline {5.2.1}Comments about Newton's Method}{39}{subsection.5.2.1}
\contentsline {paragraph}{Newton's Method may not necessarily have quadratic rate of convergence}{39}{subsection.5.2.1}
\contentsline {subsection}{\numberline {5.2.2}Constant Step-Size Analysis}{40}{subsection.5.2.2}
\contentsline {paragraph}{Step 1: Apply Lipschitz condition}{41}{proposition.5.1}
\contentsline {paragraph}{Step 2: Applying Convexity of $f$}{41}{equation.5.2.5}
\contentsline {paragraph}{Step 3: applying monotonicity of $f(x^k) - f(x^*)$}{42}{equation.5.2.5}
\contentsline {paragraph}{Step 1: Lipschitz gradient gives upper bound on $f(x^{k+1}) - f(x^k)$}{42}{proposition.5.2}
\contentsline {paragraph}{Step 2: Stronly convex gives upper bound on $f(x^*) - f(x)$}{43}{proposition.5.2}
\contentsline {paragraph}{Step 3: Re-arrange bounds on $f(x^{k+1}) - f(x^*)$}{43}{proposition.5.2}
\contentsline {paragraph}{Reading Assignment: }{43}{proposition.5.2}
\contentsline {chapter}{\numberline {6}Week6}{45}{chapter.6}
\contentsline {section}{\numberline {6.1}Monday}{45}{section.6.1}
\contentsline {subsection}{\numberline {6.1.1}Announcement}{45}{subsection.6.1.1}
\contentsline {subsection}{\numberline {6.1.2}Introduction to Quasi-Newton Method}{45}{subsection.6.1.2}
\contentsline {paragraph}{QN-Equation}{45}{equation.6.1.1}
\contentsline {paragraph}{Least-Change}{46}{equation.6.1.1}
\contentsline {subsection}{\numberline {6.1.3}Constrainted Optimization Problem}{46}{subsection.6.1.3}
\contentsline {paragraph}{Optimality Condition for (\ref {Eq:6:1})}{46}{equation.6.1.2}
\contentsline {paragraph}{Optimality condition for general function}{47}{equation.6.1.2}
\contentsline {subsection}{\numberline {6.1.4}Announcement on Assignment}{47}{subsection.6.1.4}
\contentsline {paragraph}{Optimal Algorithm for optimization}{48}{equation.6.1.4}
\contentsline {subsection}{\numberline {6.1.5}Introduction to Stochastic optimization}{49}{subsection.6.1.5}
\contentsline {section}{\numberline {6.2}Tutorial: Monday}{49}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}LP Problem}{49}{subsection.6.2.1}
\contentsline {subsection}{\numberline {6.2.2}Gauss-Newton Method}{50}{subsection.6.2.2}
\contentsline {subsection}{\numberline {6.2.3}Introduction to KKT and CQ}{51}{subsection.6.2.3}
\contentsline {section}{\numberline {6.3}Wednesday}{52}{section.6.3}
\contentsline {subsection}{\numberline {6.3.1}Review}{52}{subsection.6.3.1}
\contentsline {paragraph}{Stochastic Gradient Method}{52}{Item.43}
\contentsline {subsection}{\numberline {6.3.2}Dual-Primal of LP}{53}{subsection.6.3.2}
\contentsline {paragraph}{Recap}{53}{subsection.6.3.2}
\contentsline {paragraph}{Barrier Term}{53}{subsection.6.3.2}
\contentsline {paragraph}{Dual Problem of LP}{53}{Item.45}
\contentsline {chapter}{\numberline {7}Week7}{57}{chapter.7}
\contentsline {section}{\numberline {7.1}Monday}{57}{section.7.1}
\contentsline {subsection}{\numberline {7.1.1}Announcement}{57}{subsection.7.1.1}
\contentsline {subsection}{\numberline {7.1.2}Recap about linear programming}{57}{subsection.7.1.2}
\contentsline {paragraph}{Something about A5}{59}{Item.51}
\contentsline {paragraph}{Incremental Problem}{59}{Item.51}
\contentsline {subsection}{\numberline {7.1.3}Optimization over convex set}{60}{subsection.7.1.3}
\contentsline {paragraph}{Example}{60}{equation.7.1.1}
\contentsline {paragraph}{Project}{60}{equation.7.1.1}
\contentsline {paragraph}{Projection-based optimality condition}{60}{proposition.7.1}
\contentsline {section}{\numberline {7.2}Wednesday}{62}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}Motivation}{62}{subsection.7.2.1}
\contentsline {paragraph}{Motivation of Feasible direction method}{62}{equation.7.2.2}
\contentsline {subsection}{\numberline {7.2.2}Convex Projections}{63}{subsection.7.2.2}
\contentsline {subsection}{\numberline {7.2.3}Feasible diection method}{65}{subsection.7.2.3}
\contentsline {paragraph}{Projection Gradient Method}{67}{equation.7.2.7b}
\contentsline {paragraph}{Conditional Gradient}{67}{equation.7.2.7b}
\contentsline {chapter}{\numberline {8}Week8}{69}{chapter.8}
\contentsline {section}{\numberline {8.1}Monday}{69}{section.8.1}
\contentsline {paragraph}{Comments for P-C method in A5}{69}{section.8.1}
\contentsline {paragraph}{Comments for Incremental Gradient Method}{70}{equation.8.1.1}
\contentsline {subsection}{\numberline {8.1.1}Constraint optimization}{70}{subsection.8.1.1}
\contentsline {subsection}{\numberline {8.1.2}Inequality Constraint Problem}{71}{subsection.8.1.2}
\contentsline {section}{\numberline {8.2}Monday Tutorial: Review for CIE6010}{71}{section.8.2}
\contentsline {paragraph}{Matrix Calculus}{71}{section.8.2}
\contentsline {paragraph}{Necessary and Sufficient Optimality condition}{73}{equation.8.2.4}
\contentsline {paragraph}{Convex functions and convex sets}{75}{Item.56}
\contentsline {paragraph}{Algorithms}{76}{proposition.8.7}
\contentsline {paragraph}{Primal and Dual}{76}{proposition.8.7}
\contentsline {paragraph}{Convergence Analysis}{77}{Item.63}
\contentsline {chapter}{\numberline {9}Week9}{79}{chapter.9}
\contentsline {section}{\numberline {9.1}Monday}{79}{section.9.1}
\contentsline {paragraph}{Annonuncement}{79}{section.9.1}
\contentsline {subsection}{\numberline {9.1.1}Reviewing for KKT}{79}{subsection.9.1.1}
\contentsline {paragraph}{Constraint Qualifications}{81}{exampleT.9.2}
\contentsline {section}{\numberline {9.2}Monday Tutorial: Reviewing for Mid-term}{82}{section.9.2}
\contentsline {paragraph}{How to answer sufficient or necessary conditions during the exam? }{82}{section.9.2}
\contentsline {paragraph}{Something highlight during the exam}{82}{section.9.2}
\contentsline {chapter}{\numberline {10}Week10}{83}{chapter.10}
\contentsline {section}{\numberline {10.1}Monday}{83}{section.10.1}
\contentsline {paragraph}{Announcement}{83}{section.10.1}
\contentsline {subsection}{\numberline {10.1.1}Duality Theory}{83}{subsection.10.1.1}
\contentsline {paragraph}{Convex Program}{84}{Item.73}
\contentsline {subsection}{\numberline {10.1.2}Penalty Algorithms}{86}{subsection.10.1.2}
\contentsline {paragraph}{Logarithm Penalty}{86}{subsection.10.1.2}
\contentsline {paragraph}{Quadratic Penalty}{86}{equation.10.1.7}
\contentsline {section}{\numberline {10.2}Wednesday}{89}{section.10.2}
\contentsline {subsection}{\numberline {10.2.1}Introduction to penalty algorithms}{89}{subsection.10.2.1}
\contentsline {paragraph}{Quadratic Penalty (Courant, 1943)}{89}{equation.10.2.11}
\contentsline {paragraph}{Augmented Lagrangian Multiplier Method}{89}{equation.10.2.11}
\contentsline {subsection}{\numberline {10.2.2}Convergence Analysis}{90}{subsection.10.2.2}
\contentsline {chapter}{\numberline {11}Week11}{93}{chapter.11}
\contentsline {section}{\numberline {11.1}Monday}{93}{section.11.1}
\contentsline {paragraph}{Announcement}{93}{section.11.1}
\contentsline {subsection}{\numberline {11.1.1}Equality Constraint Problem}{93}{subsection.11.1.1}
\contentsline {paragraph}{Augmented Lagrangian}{93}{equation.11.1.1}
\contentsline {paragraph}{Viewpoint from Duality}{94}{equation.11.1.3}
\contentsline {paragraph}{Sensitivity analysis}{94}{equation.11.1.5}
\contentsline {subsection}{\numberline {11.1.2}ADMM}{96}{subsection.11.1.2}
\contentsline {section}{\numberline {11.2}Wednesday}{97}{section.11.2}
\contentsline {subsection}{\numberline {11.2.1}Comments on Assignment 6}{97}{subsection.11.2.1}
\contentsline {subsection}{\numberline {11.2.2}Inequality Constraint Problem}{98}{subsection.11.2.2}
\contentsline {subsection}{\numberline {11.2.3}Non-smooth unconstraint problem}{99}{subsection.11.2.3}
\contentsline {chapter}{\numberline {12}Week12}{101}{chapter.12}
\contentsline {section}{\numberline {12.1}Monday}{101}{section.12.1}
\contentsline {subsection}{\numberline {12.1.1}Comments on Final Project}{101}{subsection.12.1.1}
\contentsline {paragraph}{Suggested ADMM method}{102}{equation.12.1.2}
\contentsline {subsection}{\numberline {12.1.2}Trust Region Method}{102}{subsection.12.1.2}
\contentsline {paragraph}{Another application of Trust Region Problem}{103}{subsection.12.1.2}
\contentsline {section}{\numberline {12.2}Wednesday}{104}{section.12.2}
\contentsline {subsection}{\numberline {12.2.1}Trust Region problem}{104}{subsection.12.2.1}
\contentsline {paragraph}{Trust Region sub-problem}{104}{subsection.12.2.1}
\contentsline {paragraph}{Barely Pass Suggestion}{106}{proposition.12.1}
\contentsline {chapter}{\numberline {13}Conic Programming}{107}{chapter.13}
\contentsline {paragraph}{Announcement}{107}{chapter.13}
\contentsline {section}{\numberline {13.1}Introduction to Formulations}{107}{section.13.1}
\contentsline {paragraph}{General Conic Programming Problem}{107}{section.13.1}
\contentsline {paragraph}{Conic problem in dual form}{109}{equation.13.1.8}
\contentsline {section}{\numberline {13.2}Weak Duality}{110}{section.13.2}
\contentsline {paragraph}{Weak Duality for LP}{110}{section.13.2}
\contentsline {paragraph}{Weak Duality for SDP}{110}{section.13.2}
\contentsline {paragraph}{Weak Duality for SOCP}{110}{section.13.2}
\contentsfinish 
